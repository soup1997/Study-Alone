{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1yURN8yVBax7qoHttCZoDkD93TxWdaZK_","timestamp":1675066656069}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"f9Xx-jP92OgP"},"source":["# 파이토치(PyTorch)\n","\n","<img src=\"https://img1.daumcdn.net/thumb/R800x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbuUgoV%2FbtqwWZvcHHX%2Fd6XzIFBEfiuFb0UvyV4A50%2Fimg.jpg\" width=\"300\">\n","\n","- 코드 출처: https://pytorch.org/tutorials/"]},{"cell_type":"markdown","metadata":{"id":"3cxreguz2sL0"},"source":["## 파이토치의 구성요소\n","\n","- `torch`: 텐서를 생성하는 라이브러리\n","\n","- `torch.autograd`: 자동미분 기능을 제공하는 라이브러리\n","\n","- `torch.nn`: 신경망을 생성하는 라이브러리\n","\n","- `torch.multiprocessing`: 병럴처리 기능을 제공하는 라이브러리\n","\n","- `torch.utils`: 데이터 조작 등 유틸리티 기능 제공\n","\n","- `torch.legacy`(./nn/.optim): Torch로부터 포팅해온 코드\n","\n","- `torch.onnx`: ONNX(Open Neural Network Exchange)\n","\n","  - 서로 다른 프레임워크 간의 모델을 공유할 때 사용"]},{"cell_type":"markdown","metadata":{"id":"gb5O_aSvtHvb"},"source":["## 텐서(Tensors)\n","- 넘파이(NumPy)의 ndarray와 유사\n","\n","- GPU를 사용한 연산 가속도 가능"]},{"cell_type":"code","metadata":{"id":"CmKIvnx0s8G6"},"source":["import torch"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"49IHV-qJE5FI","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1675066885600,"user_tz":-540,"elapsed":624,"user":{"displayName":"조현습","userId":"00227774474014694265"}},"outputId":"19035827-d887-4d29-ee85-58e4f6189eca"},"source":["torch.__version__"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'1.13.1+cu116'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":2}]},{"cell_type":"markdown","metadata":{"id":"isUHVy-gtZeT"},"source":["### 초기화 되지 않은 행렬 "]},{"cell_type":"code","metadata":{"id":"3PqY3cZatU0D","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675066911739,"user_tz":-540,"elapsed":4,"user":{"displayName":"조현습","userId":"00227774474014694265"}},"outputId":"b075ff40-b050-49b1-99df-a7b905ab3bc4"},"source":["# empty임에도 불구하고 메모리에서 사용하던 기존 값들이 그대로 이용됨(쓰레기값)\n","x = torch.empty(4, 2)\n","print(x)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[3.7888e-34, 0.0000e+00],\n","        [3.5032e-44, 0.0000e+00],\n","        [       nan, 1.5554e-43],\n","        [1.1578e+27, 7.1463e+22]])\n"]}]},{"cell_type":"markdown","metadata":{"id":"zPCIJ2pNteZv"},"source":["### 무작위로 초기화된 행렬"]},{"cell_type":"code","metadata":{"id":"h6oPj2Q9tdYx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675066988329,"user_tz":-540,"elapsed":8,"user":{"displayName":"조현습","userId":"00227774474014694265"}},"outputId":"96797fa1-10e5-4d9b-c285-f9727f0d6f1e"},"source":["x = torch.rand(4, 2)\n","print(x)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[0.6890, 0.5422],\n","        [0.7370, 0.7210],\n","        [0.8369, 0.2938],\n","        [0.7205, 0.9653]])\n"]}]},{"cell_type":"markdown","metadata":{"id":"A5aHphIHtiJk"},"source":["### dtype이 long, 0으로 채워진 텐서"]},{"cell_type":"code","metadata":{"id":"4zykN8aMthXk","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675067019256,"user_tz":-540,"elapsed":4,"user":{"displayName":"조현습","userId":"00227774474014694265"}},"outputId":"2b00aa98-6e61-4e72-9762-e6321e22f660"},"source":["x = torch.zeros(4, 2, dtype=torch.long)\n","print(x)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[0, 0],\n","        [0, 0],\n","        [0, 0],\n","        [0, 0]])\n"]}]},{"cell_type":"code","metadata":{"id":"W4VL8C_ctu8b","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675067054569,"user_tz":-540,"elapsed":3,"user":{"displayName":"조현습","userId":"00227774474014694265"}},"outputId":"87fa94bd-a4bb-47ef-f70d-4310a0d600fe"},"source":["x = torch.tensor([3, 1, 2, 3])\n","print(x)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([3, 1, 2, 3])\n"]}]},{"cell_type":"code","metadata":{"id":"4RmVBVtIt46M","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675067076686,"user_tz":-540,"elapsed":3,"user":{"displayName":"조현습","userId":"00227774474014694265"}},"outputId":"3090eb4a-7f41-4c44-93ae-9b92a8fa693b"},"source":["x = x.new_ones(2, 4, dtype=torch.double)\n","print(x)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[1., 1., 1., 1.],\n","        [1., 1., 1., 1.]], dtype=torch.float64)\n"]}]},{"cell_type":"code","metadata":{"id":"xxskTUfGuPUe","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675067132395,"user_tz":-540,"elapsed":2,"user":{"displayName":"조현습","userId":"00227774474014694265"}},"outputId":"c0eab89a-2180-40f4-ddbc-1dcc872e3c76"},"source":["# 기존의 shape 유지\n","x = torch.randn_like(x, dtype=torch.float)\n","print(x)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[-0.8988,  2.2522, -1.0121, -1.1983],\n","        [-0.0200,  1.6317, -0.7953, -1.2101]])\n"]}]},{"cell_type":"markdown","metadata":{"id":"7j5sGxGvucpH"},"source":["### 텐서의 크기"]},{"cell_type":"code","metadata":{"id":"yy-JbqKEuYIR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675067149445,"user_tz":-540,"elapsed":2,"user":{"displayName":"조현습","userId":"00227774474014694265"}},"outputId":"73e98f2e-af21-450f-8927-cd8ea443f956"},"source":["# 텐서의 shape 확인\n","print(x.size())"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([2, 4])\n"]}]},{"cell_type":"markdown","metadata":{"id":"ehOg0eDwufru"},"source":["## 텐서의 연산(operations)"]},{"cell_type":"markdown","metadata":{"id":"j8Doc_37uh3G"},"source":["### 덧셈 1"]},{"cell_type":"code","metadata":{"id":"Rw4JCYkYuef9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675067168918,"user_tz":-540,"elapsed":3,"user":{"displayName":"조현습","userId":"00227774474014694265"}},"outputId":"dfca639d-4432-4cf5-eb76-b808157855c3"},"source":["print(x)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[-0.8988,  2.2522, -1.0121, -1.1983],\n","        [-0.0200,  1.6317, -0.7953, -1.2101]])\n"]}]},{"cell_type":"code","metadata":{"id":"Wa44ur1Nuj5U","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675067196753,"user_tz":-540,"elapsed":2,"user":{"displayName":"조현습","userId":"00227774474014694265"}},"outputId":"885aab9c-e21f-4f1d-c844-45dc64a3c108"},"source":["# 원소별 덧셈\n","y = torch.rand(2, 4)\n","print(y)\n","print(x + y)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[0.0922, 0.8710, 0.6015, 0.1448],\n","        [0.2417, 0.8044, 0.6816, 0.2639]])\n","tensor([[-0.8066,  3.1233, -0.4106, -1.0534],\n","        [ 0.2217,  2.4361, -0.1137, -0.9462]])\n"]}]},{"cell_type":"markdown","metadata":{"id":"E5gcOo-Ouo9B"},"source":["### 덧셈2"]},{"cell_type":"code","metadata":{"id":"Qx-NzJhhumZx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675067230518,"user_tz":-540,"elapsed":2,"user":{"displayName":"조현습","userId":"00227774474014694265"}},"outputId":"86e4d92c-89a3-44ef-ae3b-9d191e413cb3"},"source":["# 원소별 덧셈\n","print(torch.add(x, y))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[-0.8066,  3.1233, -0.4106, -1.0534],\n","        [ 0.2217,  2.4361, -0.1137, -0.9462]])\n"]}]},{"cell_type":"markdown","metadata":{"id":"RlvrQhLuuuIr"},"source":["### 덧셈3\n","- 결과 텐서를 인자로 제공"]},{"cell_type":"code","metadata":{"id":"lUsLAOTcur1-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675067312833,"user_tz":-540,"elapsed":3,"user":{"displayName":"조현습","userId":"00227774474014694265"}},"outputId":"5d98c829-f80d-48eb-a786-f5491549af96"},"source":["result = torch.empty(2, 4)\n","print('Original result:', result)\n","torch.add(x, y, out=result)\n","print('Now result:', result)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Original result: tensor([[3.7889e-34, 0.0000e+00, 4.1057e-01, 1.0534e+00],\n","        [2.2171e-01, 2.4361e+00, 1.1369e-01, 9.4616e-01]])\n","Now result: tensor([[-0.8066,  3.1233, -0.4106, -1.0534],\n","        [ 0.2217,  2.4361, -0.1137, -0.9462]])\n"]}]},{"cell_type":"markdown","metadata":{"id":"V6BdyZFSu2Ei"},"source":["### 덧셈4\n","- `in-place` 방식\n","\n","- (참고) in-place 방식\n","  - in-place방식으로 텐서의 값을 변경하는 연산 뒤에는 _''가 붙음\n","  - `x.copy_(y), x.t_()`"]},{"cell_type":"code","metadata":{"id":"lu8rR4WVu0wQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675067348362,"user_tz":-540,"elapsed":2,"user":{"displayName":"조현습","userId":"00227774474014694265"}},"outputId":"8712c0b1-b55e-4df9-fbc5-72ebd749845e"},"source":["print(x)\n","print(y)\n","y.add_(x) # y += x\n","print(y)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[-0.8988,  2.2522, -1.0121, -1.1983],\n","        [-0.0200,  1.6317, -0.7953, -1.2101]])\n","tensor([[0.0922, 0.8710, 0.6015, 0.1448],\n","        [0.2417, 0.8044, 0.6816, 0.2639]])\n","tensor([[-0.8066,  3.1233, -0.4106, -1.0534],\n","        [ 0.2217,  2.4361, -0.1137, -0.9462]])\n"]}]},{"cell_type":"markdown","metadata":{"id":"Uo8nsrGjOw6W"},"source":["### 그 외의 연산\n","- `torch.sub` : 뺄셈\n","\n","- `torch.mul` : 곱셉\n","\n","- `torch.div` : 나눗셈\n","\n","- `torch.mm` : 내적(dot product)"]},{"cell_type":"code","metadata":{"id":"S51kxzPTO1ER","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675067493611,"user_tz":-540,"elapsed":1029,"user":{"displayName":"조현습","userId":"00227774474014694265"}},"outputId":"50427f3f-7bed-49bf-8401-2e380445a7ff"},"source":["# 어떤 방식을 써도 동일한 결과를 출력(원소별 뺄셈)\n","\n","x = torch.tensor([[1, 3],\n","                  [5, 7]])\n","y = torch.tensor([[2, 4],\n","                  [6, 8]])\n","print(x-y)\n","print(torch.sub(x, y))\n","print(x.sub(y))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[-1, -1],\n","        [-1, -1]])\n","tensor([[-1, -1],\n","        [-1, -1]])\n","tensor([[-1, -1],\n","        [-1, -1]])\n"]}]},{"cell_type":"code","metadata":{"id":"ou0dY8mkPR24","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675067556997,"user_tz":-540,"elapsed":2,"user":{"displayName":"조현습","userId":"00227774474014694265"}},"outputId":"5a40deff-a6d0-45f6-b1e1-ab0ea5dfc0fd"},"source":["# 어떤 방식을 써도 동일한 결과를 출력(원소별 곱셈)\n","\n","x = torch.tensor([[1, 3],\n","                  [5, 7]])\n","y = torch.tensor([[2, 4],\n","                  [6, 8]])\n","print(x*y)\n","print(torch.mul(x, y))\n","print(x.mul(y))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[ 2, 12],\n","        [30, 56]])\n","tensor([[ 2, 12],\n","        [30, 56]])\n","tensor([[ 2, 12],\n","        [30, 56]])\n"]}]},{"cell_type":"code","metadata":{"id":"6RlZZBp3PbE4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675067619785,"user_tz":-540,"elapsed":391,"user":{"displayName":"조현습","userId":"00227774474014694265"}},"outputId":"22c5216a-738b-42b0-e8ce-dfb9bbc35421"},"source":["# 어떤 방식을 써도 동일한 결과를 출력(원소별 나눗셈)\n","\n","x = torch.tensor([[1, 3],\n","                  [5, 7]])\n","y = torch.tensor([[2, 4],\n","                  [6, 8]])\n","print(x/y)\n","print(torch.div(x, y))\n","print(x.div(y))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[0.5000, 0.7500],\n","        [0.8333, 0.8750]])\n","tensor([[0.5000, 0.7500],\n","        [0.8333, 0.8750]])\n","tensor([[0.5000, 0.7500],\n","        [0.8333, 0.8750]])\n"]}]},{"cell_type":"code","metadata":{"id":"7MR-ofE5P7VC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675067681107,"user_tz":-540,"elapsed":4,"user":{"displayName":"조현습","userId":"00227774474014694265"}},"outputId":"3f67110e-81fe-4710-98e9-857ca51e1ab2"},"source":["# dot product(내적, 행렬곱)\n","x = torch.tensor([[1, 3],\n","                  [5, 7]])\n","y = torch.tensor([[2, 4],\n","                  [6, 8]])\n","print(torch.mm(x, y))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[20, 28],\n","        [52, 76]])\n"]}]},{"cell_type":"markdown","metadata":{"id":"8URGwHE_NjDi"},"source":["## 텐서의 조작(manipulations)"]},{"cell_type":"markdown","metadata":{"id":"uCsdZIPTvG53"},"source":["### 인덱싱\n","- 넘파이처럼 인덱싱 사용가능"]},{"cell_type":"code","metadata":{"id":"jF2DE8kzvOs3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675067697617,"user_tz":-540,"elapsed":8,"user":{"displayName":"조현습","userId":"00227774474014694265"}},"outputId":"feec1575-45de-48a8-b7b8-372c3b0f9212"},"source":["print(x)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[1, 3],\n","        [5, 7]])\n"]}]},{"cell_type":"code","metadata":{"id":"GQtBH3r3u7c3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675067704903,"user_tz":-540,"elapsed":2,"user":{"displayName":"조현습","userId":"00227774474014694265"}},"outputId":"a4c96904-7119-4e32-e5ff-f8b1dd4b94c1"},"source":["print(x[:, 1])"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([3, 7])\n"]}]},{"cell_type":"markdown","metadata":{"id":"jEscXddKvQ5l"},"source":["### view\n","- 텐서의 크기(size)나 모양(shape)을 변경"]},{"cell_type":"code","metadata":{"id":"xwhWeqhLvKKj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675067817188,"user_tz":-540,"elapsed":2,"user":{"displayName":"조현습","userId":"00227774474014694265"}},"outputId":"626e9695-7b9c-42b9-a6b9-d0602d459571"},"source":["# numpy의 reshape와 동일\n","\n","x = torch.randn(4, 5) # 2차원 4 * 5\n","y = x.view(20) # 1차원 (20, 1)\n","z = x.view(5, -1) # 2차원 자동 계산 5 * 4\n","\n","print(x)\n","print(y)\n","print(z)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[ 1.3305, -2.2084,  0.9526, -1.5025,  0.0038],\n","        [-0.3866,  0.0362,  0.7467, -0.3228, -1.1652],\n","        [ 0.2418, -0.3464,  0.0298,  0.2302, -0.3550],\n","        [-0.2026, -0.7713,  0.7649, -0.4015, -1.0641]])\n","tensor([ 1.3305, -2.2084,  0.9526, -1.5025,  0.0038, -0.3866,  0.0362,  0.7467,\n","        -0.3228, -1.1652,  0.2418, -0.3464,  0.0298,  0.2302, -0.3550, -0.2026,\n","        -0.7713,  0.7649, -0.4015, -1.0641])\n","tensor([[ 1.3305, -2.2084,  0.9526, -1.5025],\n","        [ 0.0038, -0.3866,  0.0362,  0.7467],\n","        [-0.3228, -1.1652,  0.2418, -0.3464],\n","        [ 0.0298,  0.2302, -0.3550, -0.2026],\n","        [-0.7713,  0.7649, -0.4015, -1.0641]])\n"]}]},{"cell_type":"markdown","metadata":{"id":"iBY_wuIRvf5j"},"source":["### item\n","- 텐서에 값이 단 하나라도 존재하면 숫자값을 얻을 수 있음\n"]},{"cell_type":"code","metadata":{"id":"E0W24QqpvcmV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675067881437,"user_tz":-540,"elapsed":4,"user":{"displayName":"조현습","userId":"00227774474014694265"}},"outputId":"c8aca3c2-3c41-475d-97f2-2f9801dbfc8f"},"source":["x = torch.randn(1)\n","print(x)\n","print(x.item())\n","print(x.dtype)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([1.1660])\n","1.166015625\n","torch.float32\n"]}]},{"cell_type":"markdown","metadata":{"id":"V1sCUVwC3Nua"},"source":["- 스칼라값 하나만 존재해야함"]},{"cell_type":"code","metadata":{"id":"jl4_FAgd3Lt9","colab":{"base_uri":"https://localhost:8080/","height":248},"executionInfo":{"status":"error","timestamp":1675067943391,"user_tz":-540,"elapsed":369,"user":{"displayName":"조현습","userId":"00227774474014694265"}},"outputId":"15529336-e14b-4999-ddb8-e4843a6094a8"},"source":["x = torch.randn(2)\n","print(x)\n","print(x.item()) # ValueError: only one element tensors can be converted to Python scalars\n","print(x.dtype)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([-0.0599, -0.0981])\n"]},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-32-7c023f92a1c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: only one element tensors can be converted to Python scalars"]}]},{"cell_type":"markdown","metadata":{"id":"uThndsy5M6wM"},"source":["### squeeze \n","- 차원을 축소(제거)"]},{"cell_type":"code","metadata":{"id":"OF3rOavnRxgM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675068032871,"user_tz":-540,"elapsed":6,"user":{"displayName":"조현습","userId":"00227774474014694265"}},"outputId":"3bf8468c-8cd9-4787-c73f-fa53bafe9b71"},"source":["# squeeze의 경우 1인차원을 제거함\n","ts = torch.rand(1, 3, 3)\n","print(ts)\n","ts.shape"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[[0.7135, 0.8551, 0.6796],\n","         [0.7585, 0.8866, 0.4924],\n","         [0.4993, 0.3889, 0.6555]]])\n"]},{"output_type":"execute_result","data":{"text/plain":["torch.Size([1, 3, 3])"]},"metadata":{},"execution_count":35}]},{"cell_type":"code","metadata":{"id":"Y2jq0jHJR5Jw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675068034412,"user_tz":-540,"elapsed":2,"user":{"displayName":"조현습","userId":"00227774474014694265"}},"outputId":"26f67d2d-3956-4975-8cd7-308028e9dd69"},"source":["t = ts.squeeze()\n","print(t)\n","print(t.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[0.7135, 0.8551, 0.6796],\n","        [0.7585, 0.8866, 0.4924],\n","        [0.4993, 0.3889, 0.6555]])\n","torch.Size([3, 3])\n"]}]},{"cell_type":"markdown","metadata":{"id":"COv-dnTYNJ8Z"},"source":["### unsqueeze\n","- 차원을 증가(생성)"]},{"cell_type":"code","metadata":{"id":"PFxaHGY1NOBo","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675068138937,"user_tz":-540,"elapsed":7,"user":{"displayName":"조현습","userId":"00227774474014694265"}},"outputId":"1214a2e2-26f3-4075-f814-35ad38e127e5"},"source":["ts = torch.rand(1, 3, 3)\n","print(ts)\n","print(ts.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[[0.8953, 0.6179, 0.1565],\n","         [0.0158, 0.3990, 0.6302],\n","         [0.2968, 0.2284, 0.7108]]])\n","torch.Size([1, 3, 3])\n"]}]},{"cell_type":"code","metadata":{"id":"b6sa4tJ7SA8G","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675068299952,"user_tz":-540,"elapsed":489,"user":{"displayName":"조현습","userId":"00227774474014694265"}},"outputId":"c681a0e6-25f1-4ea3-8be6-7438d4f194db"},"source":["# 특정 위치에 1인 차원을 추가함, 첫번째 차원의 인덱스를 의미하는 숫자 0을 인자로 넣으면 첫번째 차원에 1인 차원이 추가됨\n","t = ts.unsqueeze(dim=0) # dim\n","print(t)\n","print(t.shape) # 3차원 행렬 --> 4차원 행렬"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[[[0.8953, 0.6179, 0.1565],\n","          [0.0158, 0.3990, 0.6302],\n","          [0.2968, 0.2284, 0.7108]]]])\n","torch.Size([1, 1, 3, 3])\n"]}]},{"cell_type":"markdown","metadata":{"id":"_C_oa9JANOa6"},"source":["### stack\n","- 텐서간 결합"]},{"cell_type":"code","metadata":{"id":"f3x_XaUYNOuc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675068399363,"user_tz":-540,"elapsed":2,"user":{"displayName":"조현습","userId":"00227774474014694265"}},"outputId":"c25b8792-e9f9-400b-f70a-a72f749f07ff"},"source":["x = torch.FloatTensor([1, 4])\n","y = torch.FloatTensor([2, 5])\n","z = torch.FloatTensor([3, 6])\n","\n","print(x)\n","print(y)\n","print(z)\n","print('')\n","\n","print(torch.stack([x, y, z]))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([1., 4.])\n","tensor([2., 5.])\n","tensor([3., 6.])\n","\n","tensor([[1., 4.],\n","        [2., 5.],\n","        [3., 6.]])\n"]}]},{"cell_type":"markdown","metadata":{"id":"XmJscbfg35-c"},"source":["### cat\n","- 텐서를 결합하는 메소드(concatenate)\n","\n","- 넘파이의 `stack`과 유사하지만, 쌓을 dim이 존재해야함\n","  - 예를 들어, 해당 차원을 늘려준 후 결합\n"]},{"cell_type":"code","metadata":{"id":"Mv3zlaNm37P1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675068441190,"user_tz":-540,"elapsed":7,"user":{"displayName":"조현습","userId":"00227774474014694265"}},"outputId":"01b72abb-2d38-4908-fda0-4b8f3515f661"},"source":["a = torch.randn(1, 1, 3, 3)\n","b = torch.randn(1, 1, 3, 3)\n","c = torch.cat((a, b), dim=0)\n","print(c)\n","print(c.size())"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[[[-7.9860e-01,  1.8777e+00, -1.3486e+00],\n","          [ 1.6463e-05,  6.9023e-01,  7.0403e-01],\n","          [ 1.2387e+00,  4.6864e-03, -4.7063e-01]]],\n","\n","\n","        [[[-2.6164e-03, -4.1648e-01, -3.7962e-01],\n","          [ 3.0846e-01,  5.4750e-01, -3.9554e-01],\n","          [ 2.3267e-01, -2.5130e-01, -1.2356e+00]]]])\n","torch.Size([2, 1, 3, 3])\n"]}]},{"cell_type":"code","metadata":{"id":"69M5jY60S7Mi","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675068498759,"user_tz":-540,"elapsed":2,"user":{"displayName":"조현습","userId":"00227774474014694265"}},"outputId":"bf557543-c1bd-4ea1-b81c-a4089c9b9645"},"source":["a = torch.randn(1, 3, 3)\n","b = torch.randn(1, 3, 3)\n","c = torch.cat((a, b), dim=1)\n","print(c)\n","print(c.size())"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[[-6.1770e-01,  2.3351e+00, -1.8973e-03],\n","         [-1.1717e+00, -4.2597e-01, -4.4078e-01],\n","         [ 4.9516e-02,  2.8294e-01, -1.3162e+00],\n","         [-5.2202e-01,  9.0536e-01,  2.1889e+00],\n","         [ 1.1652e+00,  2.3294e+00, -1.5464e+00],\n","         [ 5.4411e-01, -1.5445e+00, -3.0257e-01]]])\n","torch.Size([1, 6, 3])\n"]}]},{"cell_type":"markdown","metadata":{"id":"7gGXnOAqQTmG"},"source":["### chunk\n","- 텐서를 여러 개로 나눌 때 사용\n","\n","- 몇 개의 텐서로 나눌 것이냐"]},{"cell_type":"code","metadata":{"id":"pNV80VzPQZgG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675068581372,"user_tz":-540,"elapsed":2,"user":{"displayName":"조현습","userId":"00227774474014694265"}},"outputId":"1c7aec0c-0e45-492f-bda5-ea71d91c2bd9"},"source":["tensor = torch.rand(3, 6)\n","t1, t2, t3 = torch.chunk(tensor, 3, dim=1) # chunk의 갯수를 3으로 지정(3등분), 기준 dimension은 1\n","\n","print(tensor)\n","print(t1)\n","print(t2)\n","print(t3)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[0.5058, 0.4546, 0.0687, 0.1016, 0.2972, 0.7453],\n","        [0.0908, 0.1276, 0.0432, 0.1082, 0.8949, 0.9236],\n","        [0.5358, 0.5510, 0.7335, 0.4014, 0.3751, 0.8133]])\n","tensor([[0.5058, 0.4546],\n","        [0.0908, 0.1276],\n","        [0.5358, 0.5510]])\n","tensor([[0.0687, 0.1016],\n","        [0.0432, 0.1082],\n","        [0.7335, 0.4014]])\n","tensor([[0.2972, 0.7453],\n","        [0.8949, 0.9236],\n","        [0.3751, 0.8133]])\n"]}]},{"cell_type":"markdown","metadata":{"id":"7U0Qb0jWQgm-"},"source":["### split\n","- `chunk`와 동일한 기능이지만 조금 다름\n","\n","- 하나의 텐서당 크기가 얼마이냐"]},{"cell_type":"code","metadata":{"id":"1V6DDnLVQqxz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675068782197,"user_tz":-540,"elapsed":374,"user":{"displayName":"조현습","userId":"00227774474014694265"}},"outputId":"2a8442e9-60d2-4c77-a9e4-52791a3d3a08"},"source":["tensor = torch.rand(3, 6)\n","t1, t2 =  torch.split(tensor, 4, dim=1) # dimension을 기준으로 얼마만큼의 사이즈(4)까지 자를 것인가 설정, 기준 dimension은 1\n","\n","print(tensor)\n","print(t1)\n","print(t2)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[0.9480, 0.1811, 0.6265, 0.3434, 0.3607, 0.9107],\n","        [0.1211, 0.6908, 0.4410, 0.8885, 0.7970, 0.0994],\n","        [0.8760, 0.8186, 0.4344, 0.2083, 0.9708, 0.7559]])\n","tensor([[0.9480, 0.1811, 0.6265, 0.3434],\n","        [0.1211, 0.6908, 0.4410, 0.8885],\n","        [0.8760, 0.8186, 0.4344, 0.2083]])\n","tensor([[0.3607, 0.9107],\n","        [0.7970, 0.0994],\n","        [0.9708, 0.7559]])\n"]}]},{"cell_type":"markdown","metadata":{"id":"estSwhCgvta6"},"source":["### torch ↔ numpy\n","- Torch Tensor(텐서)를 Numpy array(배열)로 변환 가능\n","\n","  - `numpy()`\n","  - `from_numpy()`\n","\n","- (참고)\n","  - Tensor가 CPU상에 있다면 Numpy 배열은 메모리 공간을 공유하므로 하나가 변하면, 다른 하나도 변함"]},{"cell_type":"code","metadata":{"id":"VxHI7c_yvmAT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675069030281,"user_tz":-540,"elapsed":5,"user":{"displayName":"조현습","userId":"00227774474014694265"}},"outputId":"f8555505-9fb1-41e3-f624-9c3213987fb9"},"source":["import numpy as np\n","a = torch.ones(7)\n","aa = np.ones(7)\n","print(a)\n","print(aa)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([1., 1., 1., 1., 1., 1., 1.])\n","[1. 1. 1. 1. 1. 1. 1.]\n"]}]},{"cell_type":"code","metadata":{"id":"whbrhokHwJ3A","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675069032114,"user_tz":-540,"elapsed":2,"user":{"displayName":"조현습","userId":"00227774474014694265"}},"outputId":"7f108deb-e6aa-40e3-c661-0e1af2ee1cfb"},"source":["b = a.numpy()\n","print(b)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[1. 1. 1. 1. 1. 1. 1.]\n"]}]},{"cell_type":"code","metadata":{"id":"5StIhUWDwQjA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675069032502,"user_tz":-540,"elapsed":2,"user":{"displayName":"조현습","userId":"00227774474014694265"}},"outputId":"66b0d4bf-57be-4932-f2f1-0af44ba60650"},"source":["a.add_(1) # a += 1(in-place 방식)\n","print(a)\n","print(b) # Tensor가 CPU상에 있다면 Numpy 배열은 메모리 공간을 공유하므로 하나가 변하면, 다른 하나도 변함"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([2., 2., 2., 2., 2., 2., 2.])\n","[2. 2. 2. 2. 2. 2. 2.]\n"]}]},{"cell_type":"code","metadata":{"id":"3RNS5-cRwTt8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675069089786,"user_tz":-540,"elapsed":2,"user":{"displayName":"조현습","userId":"00227774474014694265"}},"outputId":"55b7c479-67b4-4fb7-82a6-89038e69476d"},"source":["a = np.ones(7)\n","b = torch.from_numpy(a)\n","np.add(a, 1, out=a) # out의 의미: 연산 결과를 변수 a에 저장\n","print(a)\n","print(b) # Tensor가 CPU상에 있다면 Numpy 배열은 메모리 공간을 공유하므로 하나가 변하면, 다른 하나도 변함"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[2. 2. 2. 2. 2. 2. 2.]\n","tensor([2., 2., 2., 2., 2., 2., 2.], dtype=torch.float64)\n"]}]},{"cell_type":"markdown","metadata":{"id":"v-ZaxSvLxEej"},"source":["## CUDA Tensors\n","- `.to` 메소드를 사용하여 텐서를 어떠한 장치로도 옮길 수 있음\n","  - 예) cpu, gpu"]},{"cell_type":"code","metadata":{"id":"xkaQznCRxpUj"},"source":["import torch"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SCnC0x2Rxpbk","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675069260823,"user_tz":-540,"elapsed":457,"user":{"displayName":"조현습","userId":"00227774474014694265"}},"outputId":"e1a7c121-b314-4a41-ed6f-7675d31edf00"},"source":["x = torch.randn(1)\n","print(x.item())\n","print(x.dtype)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1.3161771297454834\n","torch.float32\n"]}]},{"cell_type":"code","metadata":{"id":"GcSsFLkDw-nI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675069437736,"user_tz":-540,"elapsed":355,"user":{"displayName":"조현습","userId":"00227774474014694265"}},"outputId":"34ac6ab4-5f8b-49cf-85ff-7e672f1b4b75"},"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(device)\n","\n","y = torch.ones_like(x, device=device) # y를 gpu환경에 할당\n","x = x.to(device) # 만들어진 x를 gpu환경으로 옮김\n","z = x + y\n","print(z)\n","print(z.to(\"cpu\", dtype=torch.double)) # 만들어진 z를 cpu환경으로 옮김"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["cuda\n","tensor([2.3162], device='cuda:0')\n","tensor([2.3162], dtype=torch.float64)\n"]}]},{"cell_type":"markdown","metadata":{"id":"NKqiGvLWx2nk"},"source":["## AUTOGRAD (자동미분)\n","- autograd 패키지는 Tensor의 모든 연산에 대해 **자동 미분** 제공\n","\n","- 이는 코드를 어떻게 작성하여 실행하느냐에 따라 역전파가 정의된다는 뜻\n","\n","- backprop를 위한 미분값을 자동으로 계산"]},{"cell_type":"markdown","metadata":{"id":"0zH41l-MyMHi"},"source":["### Tensor\n","\n","- data: tensor형태의 데이터\n","\n","- grad: data가 겨쳐온 layer에 대한 미분값 저장\n","\n","- grad_fn: 미분값을 계산한 함수에 대한 정보 저장 (어떤 함수에 대해서 backprop 했는지)\n","\n","- `requires_grad` 속성을 `True`로 설정하면, 해당 텐서에서 이루어지는 모든 연산들을 추적하기 시작\n","\n","- 계산이 완료된 후, `.backward()`를 호출하면 자동으로 `gradient`를 계산할 수 있으며, `.grad` 속성에 누적됨\n","\n","- 기록을 추적하는 것을 중단하게 하려면, `.detach()`를 호출하여 연산기록으로부터 분리\n","\n","- 기록을 추적하는 것을 방지하기 위해 코드 블럭을 `with torch.no_grad():`로 감싸면 `gradient`는 필요없지만, `requires_grad=True`로 설정되어 학습 가능한 매개변수를 갖는 모델을 평가(evaluate)할 때 유용\n","\n","- Autograd 구현에서 매우 중요한 클래스 : `Function` 클래스"]},{"cell_type":"code","metadata":{"id":"ipdk_1jfx47I","executionInfo":{"status":"ok","timestamp":1675154810261,"user_tz":-540,"elapsed":2165,"user":{"displayName":"조현습","userId":"00227774474014694265"}}},"source":["import torch"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"ljNU-r9p0Rpo","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675154835184,"user_tz":-540,"elapsed":433,"user":{"displayName":"조현습","userId":"00227774474014694265"}},"outputId":"50575540-e003-47b2-bea6-873f4af6c8c2"},"source":["x = torch.ones(3, 3, requires_grad=True)\n","print(x)"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[1., 1., 1.],\n","        [1., 1., 1.],\n","        [1., 1., 1.]], requires_grad=True)\n"]}]},{"cell_type":"code","metadata":{"id":"or6sQ4EB0UYz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675154845072,"user_tz":-540,"elapsed":3,"user":{"displayName":"조현습","userId":"00227774474014694265"}},"outputId":"ac2a462a-3e6d-4b14-fa17-54ec1fab2e5f"},"source":["y = x+5\n","print(y)"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[6., 6., 6.],\n","        [6., 6., 6.],\n","        [6., 6., 6.]], grad_fn=<AddBackward0>)\n"]}]},{"cell_type":"code","metadata":{"id":"PuQ7xDmu0Wpj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675154870587,"user_tz":-540,"elapsed":3,"user":{"displayName":"조현습","userId":"00227774474014694265"}},"outputId":"4b9a8931-f702-4da7-dbb9-6fd623d38b11"},"source":["print(y.grad_fn)"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["<AddBackward0 object at 0x7fe891f14b80>\n"]}]},{"cell_type":"code","metadata":{"id":"6_2iM-Zq0ZdG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675154902179,"user_tz":-540,"elapsed":3,"user":{"displayName":"조현습","userId":"00227774474014694265"}},"outputId":"b73216d3-825f-4dc2-97b7-0c9772eac9c9"},"source":["z = y * y * 2\n","out = z.mean()\n","print(z, out)"],"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[72., 72., 72.],\n","        [72., 72., 72.],\n","        [72., 72., 72.]], grad_fn=<MulBackward0>) tensor(72., grad_fn=<MeanBackward0>)\n"]}]},{"cell_type":"markdown","metadata":{"id":"2aZ8SWn_0nqt"},"source":["- `requires_grad_(...)`는 기존 텐서의 `requires_grad`값을 바꿔치기(`in-place`)하여 변경"]},{"cell_type":"code","metadata":{"id":"mHGROgrM0ebO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675155026826,"user_tz":-540,"elapsed":5,"user":{"displayName":"조현습","userId":"00227774474014694265"}},"outputId":"0d14016c-6fc4-49de-d41d-c1399c460062"},"source":["a = torch.randn(3, 3)\n","a = (a*3) / (a - 1)\n","print(a.requires_grad) # 추적 X\n","\n","a.requires_grad_(True)\n","print(a.requires_grad) # 추적 시작\n","\n","b = (a * a).sum()\n","print(b.grad_fn) # <SumBackward0 object at 0x7fe81117f550>"],"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["False\n","True\n","<SumBackward0 object at 0x7fe81117f550>\n"]}]},{"cell_type":"markdown","metadata":{"id":"KiEn_stZ1VgU"},"source":["### 기울기(Gradient)\n","- 역전파: `.backward()`를 통해 역전파 계산 가능"]},{"cell_type":"code","metadata":{"id":"1tdoN9p-1kn4","executionInfo":{"status":"ok","timestamp":1675155092688,"user_tz":-540,"elapsed":593,"user":{"displayName":"조현습","userId":"00227774474014694265"}}},"source":["out.backward()"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"CixGTXbV1B9p","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675155114054,"user_tz":-540,"elapsed":453,"user":{"displayName":"조현습","userId":"00227774474014694265"}},"outputId":"2ee30987-8131-46f9-ddbe-b73fc6477b6d"},"source":["print(x.grad)"],"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[2.6667, 2.6667, 2.6667],\n","        [2.6667, 2.6667, 2.6667],\n","        [2.6667, 2.6667, 2.6667]])\n"]}]},{"cell_type":"code","metadata":{"id":"SY63Mcc-1iNI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675155153973,"user_tz":-540,"elapsed":3,"user":{"displayName":"조현습","userId":"00227774474014694265"}},"outputId":"9464491d-6d6f-4e60-d27e-d37759b83189"},"source":["x = torch.randn(3, requires_grad=True)\n","y = x*2\n","while y.data.norm() < 1000:\n","  y = y * 2\n","print(y)"],"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([1759.6780,  317.8589,  347.0760], grad_fn=<MulBackward0>)\n"]}]},{"cell_type":"code","metadata":{"id":"YPaVAbIT3gx_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675155478797,"user_tz":-540,"elapsed":4,"user":{"displayName":"조현습","userId":"00227774474014694265"}},"outputId":"7a922e8e-5b5e-4cca-cac8-f226b09bc71a"},"source":["# output이 scalar이어야 backward 연산이 됩니다.\n","\n","v = torch.tensor([0.1, 1.0, 0.00001], dtype=torch.float)\n","y.backward(v)\n","print(x.grad)"],"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([1.0240e+02, 1.0240e+03, 1.0240e-02])\n"]}]},{"cell_type":"markdown","metadata":{"id":"0b9amArPXtcX"},"source":["- `with torch.no_grad()`를 사용하여 gradient의 업데이트를 하지 않음"]},{"cell_type":"code","metadata":{"id":"weeIe5_Z3jVe","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675156757041,"user_tz":-540,"elapsed":829,"user":{"displayName":"조현습","userId":"00227774474014694265"}},"outputId":"0bb79589-762a-4543-cb5f-1037be26c286"},"source":["print(x.requires_grad)\n","print((x**2).requires_grad)\n","\n","with torch.no_grad():\n","  print((x**2).requires_grad)"],"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["True\n","True\n","False\n"]}]},{"cell_type":"markdown","metadata":{"id":"bLcTLVRSmCdH"},"source":["- `detach()`: 내용물(content)은 같지만 require_grad가 다른 새로운 Tensor를 가져올 때"]},{"cell_type":"code","metadata":{"id":"ALcth7Ew3l7H","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675156890971,"user_tz":-540,"elapsed":359,"user":{"displayName":"조현습","userId":"00227774474014694265"}},"outputId":"bed48ebd-ef20-4843-8c50-89bdeca6da37"},"source":["print(x.requires_grad)\n","y = x.detach()\n","print(y.requires_grad)\n","print(x.eq(y).all()) # x값과 y값은 동일하지만 requires_grad 차이만 존재함"],"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["True\n","False\n","tensor(True)\n"]}]},{"cell_type":"markdown","metadata":{"id":"NSarysrqBh9D"},"source":["### 자동 미분 흐름 다시 보기(1)\n","- 계산 흐름  \n","  $a \\rightarrow b  \\rightarrow c  \\rightarrow out $\n","\n","<br>\n","\n","## $\\quad \\frac{\\partial out}{\\partial a} = ?$\n","- `backward()`를 통해  \n","  $a \\leftarrow b  \\leftarrow c  \\leftarrow out $을 계산하면  \n","    $\\frac{\\partial out}{\\partial a}$값이 `a.grad`에 채워짐\n"]},{"cell_type":"code","metadata":{"id":"NUAc1etP3oBc","executionInfo":{"status":"ok","timestamp":1675156968970,"user_tz":-540,"elapsed":394,"user":{"displayName":"조현습","userId":"00227774474014694265"}}},"source":["import torch"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"tCW7dq9uB89T","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675156975188,"user_tz":-540,"elapsed":470,"user":{"displayName":"조현습","userId":"00227774474014694265"}},"outputId":"ffbb4f8b-59b0-4882-c5b1-942facc2b5f5"},"source":["a = torch.ones(2, 2)\n","print(a)"],"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[1., 1.],\n","        [1., 1.]])\n"]}]},{"cell_type":"code","metadata":{"id":"-AyyGy49FLz9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675157160640,"user_tz":-540,"elapsed":979,"user":{"displayName":"조현습","userId":"00227774474014694265"}},"outputId":"71e23328-39b0-41b2-947c-ed5178410b54"},"source":["a = torch.ones(2, 2, requires_grad=True)\n","print(a)"],"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[1., 1.],\n","        [1., 1.]], requires_grad=True)\n"]}]},{"cell_type":"code","metadata":{"id":"SmmJa-hvFPGH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675157193690,"user_tz":-540,"elapsed":370,"user":{"displayName":"조현습","userId":"00227774474014694265"}},"outputId":"d0babc0f-3d0d-410d-ac26-3a9a196e02b7"},"source":["print(\"a.data:\", a)\n","print(\"a.grad:\", a.grad) # 아직 backward를 이용하여 gradient를 구하지 않았기 때문에 None\n","print(\"a.grad_fn:\", a.grad_fn) # 아직 backward를 이용하여 gradient를 구하지 않았기 때문에 None"],"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["a.data: tensor([[1., 1.],\n","        [1., 1.]], requires_grad=True)\n","a.grad: None\n","a.grad_fn: None\n"]}]},{"cell_type":"markdown","metadata":{"id":"BCwhTsiHGCmG"},"source":["- $b = a + 2$"]},{"cell_type":"code","metadata":{"id":"iUPt042iF9V1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675157252654,"user_tz":-540,"elapsed":562,"user":{"displayName":"조현습","userId":"00227774474014694265"}},"outputId":"4103b9cc-4656-41e1-a158-78ea22b64e52"},"source":["b = a + 2\n","print(b)"],"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[3., 3.],\n","        [3., 3.]], grad_fn=<AddBackward0>)\n"]}]},{"cell_type":"markdown","metadata":{"id":"6cw2zoq9GHLF"},"source":["- $c = b^2$ "]},{"cell_type":"code","metadata":{"id":"FRDS6gP0GFZG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675157263154,"user_tz":-540,"elapsed":750,"user":{"displayName":"조현습","userId":"00227774474014694265"}},"outputId":"2349a80d-6e7e-452a-81df-4bab910162e8"},"source":["c = b**2\n","print(c)"],"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[9., 9.],\n","        [9., 9.]], grad_fn=<PowBackward0>)\n"]}]},{"cell_type":"code","metadata":{"id":"VynoiUywGSwh","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675157281062,"user_tz":-540,"elapsed":689,"user":{"displayName":"조현습","userId":"00227774474014694265"}},"outputId":"44348fd0-104d-4691-9ef6-789c6e86885a"},"source":["out = c.sum()\n","print(out)"],"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(36., grad_fn=<SumBackward0>)\n"]}]},{"cell_type":"code","metadata":{"id":"v3ryJon9GeMn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675157301129,"user_tz":-540,"elapsed":693,"user":{"displayName":"조현습","userId":"00227774474014694265"}},"outputId":"06db5298-c67b-4817-ada8-70ab1a093d70"},"source":["print(out)\n","out.backward()"],"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(36., grad_fn=<SumBackward0>)\n"]}]},{"cell_type":"markdown","metadata":{"id":"f0aoNsPDHsoG"},"source":["- a의 `grad_fn`이 None인 이유  \n","  직접적으로 계산한 부분이 없었기 때문"]},{"cell_type":"code","metadata":{"id":"bccI4vIWGgqj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675157367306,"user_tz":-540,"elapsed":628,"user":{"displayName":"조현습","userId":"00227774474014694265"}},"outputId":"4aa57f92-9b45-42aa-a3a2-1095d6eeb62e"},"source":["print(\"a.data:\", a)\n","print(\"a.grad:\", a.grad)\n","print(\"a.grad_fn:\", a.grad_fn)"],"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["a.data: tensor([[1., 1.],\n","        [1., 1.]], requires_grad=True)\n","a.grad: tensor([[6., 6.],\n","        [6., 6.]])\n","a.grad_fn: None\n"]}]},{"cell_type":"code","metadata":{"id":"oka1mkadHq-N","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675157455791,"user_tz":-540,"elapsed":630,"user":{"displayName":"조현습","userId":"00227774474014694265"}},"outputId":"c74ea9d9-3788-4ccc-833d-37c6b39e2e98"},"source":["print(\"b.data:\", b.data)\n","print(\"b.grad:\", b.grad)\n","print(\"b.grad_fn:\", b.grad_fn)"],"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["b.data: tensor([[3., 3.],\n","        [3., 3.]])\n","b.grad: None\n","b.grad_fn: <AddBackward0 object at 0x7fe81117f460>\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-26-403b26da0b13>:2: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at aten/src/ATen/core/TensorBody.h:480.)\n","  print(\"b.grad:\", b.grad)\n"]}]},{"cell_type":"code","metadata":{"id":"ZiYNajdLccUF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675157473298,"user_tz":-540,"elapsed":537,"user":{"displayName":"조현습","userId":"00227774474014694265"}},"outputId":"b600b0bf-1f6d-415c-9505-673e1c2ec549"},"source":["print(\"c.data:\", c.data)\n","print(\"c.grad:\", c.grad)\n","print(\"c.grad_fn:\", c.grad_fn)"],"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["c.data: tensor([[9., 9.],\n","        [9., 9.]])\n","c.grad: None\n","c.grad_fn: <PowBackward0 object at 0x7fe811187100>\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-27-035c04ca563a>:2: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at aten/src/ATen/core/TensorBody.h:480.)\n","  print(\"c.grad:\", c.grad)\n"]}]},{"cell_type":"code","metadata":{"id":"BcLoMYite0vU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675157504730,"user_tz":-540,"elapsed":490,"user":{"displayName":"조현습","userId":"00227774474014694265"}},"outputId":"99aa213e-bb5d-4502-aa32-b009faf2d2c5"},"source":["print(\"out.data:\", out.data)\n","print(\"out.grad:\", out.grad)\n","print(\"out.grad_fn:\", out.grad_fn)"],"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["out.data: tensor(36.)\n","out.grad: None\n","out.grad_fn: <SumBackward0 object at 0x7fe811163cd0>\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-28-cabb8f7e327b>:2: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at aten/src/ATen/core/TensorBody.h:480.)\n","  print(\"out.grad:\", out.grad)\n"]}]},{"cell_type":"markdown","metadata":{"id":"qZXgwviHfovj"},"source":["### 자동 미분 흐름 다시 보기(2)\n","- `grad`값을 넣어서 `backward`\n","\n","- 아래의 코드에서 `.grad`값이 None은 gradient값이 필요하지 않기 때문"]},{"cell_type":"code","metadata":{"id":"bB6DCYXRfcI_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675157540888,"user_tz":-540,"elapsed":540,"user":{"displayName":"조현습","userId":"00227774474014694265"}},"outputId":"fb137d44-f0e7-4edd-caf0-552194bc6ab6"},"source":["x = torch.ones(3, requires_grad=True)\n","y = x ** 2\n","z = y ** 2 + x\n","out = z.sum()\n","print(out)"],"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(6., grad_fn=<SumBackward0>)\n"]}]},{"cell_type":"code","metadata":{"id":"AVo-glm8fvFv","executionInfo":{"status":"ok","timestamp":1675157587096,"user_tz":-540,"elapsed":711,"user":{"displayName":"조현습","userId":"00227774474014694265"}}},"source":["grad = torch.tensor([0.1, 1, 100])\n","z.backward(grad)"],"execution_count":30,"outputs":[]},{"cell_type":"code","metadata":{"id":"tdBklrepf2qq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675157604614,"user_tz":-540,"elapsed":363,"user":{"displayName":"조현습","userId":"00227774474014694265"}},"outputId":"31979c05-90c0-4a48-e47a-90256ba5a2f9"},"source":["print(\"x.data:\", x.data)\n","print(\"x.grad:\", x.grad)\n","print(\"x.grad_fn:\", x.grad_fn)"],"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["x.data: tensor([1., 1., 1.])\n","x.grad: tensor([  0.5000,   5.0000, 500.0000])\n","x.grad_fn: None\n"]}]},{"cell_type":"code","metadata":{"id":"HQvUGlfRf7jU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675157656006,"user_tz":-540,"elapsed":366,"user":{"displayName":"조현습","userId":"00227774474014694265"}},"outputId":"2d85bbc7-0e1d-4548-e1bb-a9440771ed46"},"source":["print(\"y.data:\", y.data)\n","print(\"y.grad:\", y.grad)\n","print(\"y.grad_fn:\", y.grad_fn)"],"execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["y.data: tensor([1., 1., 1.])\n","y.grad: None\n","y.grad_fn: <PowBackward0 object at 0x7fe81117f760>\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-32-b63d98fcbc02>:2: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at aten/src/ATen/core/TensorBody.h:480.)\n","  print(\"y.grad:\", y.grad)\n"]}]},{"cell_type":"code","metadata":{"id":"h7TFHdMfgxvW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675157682875,"user_tz":-540,"elapsed":618,"user":{"displayName":"조현습","userId":"00227774474014694265"}},"outputId":"0bd45f37-d15f-4dc9-90b7-026534fb7c0b"},"source":["print(\"z.data:\", z.data)\n","print(\"z.grad:\", z.grad)\n","print(\"z.grad_fn:\", z.grad_fn)"],"execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":["z.data: tensor([2., 2., 2.])\n","z.grad: None\n","z.grad_fn: <AddBackward0 object at 0x7fe8111dfdf0>\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-33-e6bf01067a56>:2: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at aten/src/ATen/core/TensorBody.h:480.)\n","  print(\"z.grad:\", z.grad)\n"]}]},{"cell_type":"markdown","metadata":{"id":"DKv-osmNmWiA"},"source":["## nn & nn.functional\n","\n","- 두 패키지가 같은 기능이지만 방식이 조금 다름\n","\n","- 위의 `autograd` 관련 작업들을 두 패키지를 통해 진행할 수 있음\n","\n","- 텐서를 직접 다룰 때 `requires_grad`와 같은 방식으로 진행할 수 있음\n","\n","- 결론적으로, `torch.nn`은 attribute를 활용해 state를 저장하고 활용하고,  \n","  `torch.nn.functional`로 구현한 함수의 경우에는 인스턴스화 시킬 필요 없이 사용이 가능\n"," \n"]},{"cell_type":"markdown","metadata":{"id":"jk8fkKq3nWP1"},"source":["### nn 패키지\n","\n","- 주로 가중치(weights), 편향(bias)값들이 내부에서 자동으로 생성되는 레이어들을 사용할 때  \n","  - 따라서, `weight`값들을 직접 선언 안함\n","\n","- 예시\n","  - Containers\n","\n","  - Convolution Layers\n","\n","  - Pooling layers\n","\n","  - Padding Layers\n","\n","  - Non-linear Activations (weighted sum, nonlinearity)\n","\n","  - Non-linear Activations (other)\n","\n","  - Normalization Layers\n","\n","  - Recurrent Layers\n","\n","  - Transformer Layers\n","\n","  - Linear Layers\n","\n","  - Dropout Layers\n","\n","  - Sparse Layers\n","\n","  - Distance Functions\n","\n","  - Loss Functions\n","\n","  - ..\n","- https://pytorch.org/docs/stable/nn.html\n","\n"]},{"cell_type":"code","metadata":{"id":"8tEtWHAsmZMy","executionInfo":{"status":"ok","timestamp":1675157816217,"user_tz":-540,"elapsed":909,"user":{"displayName":"조현습","userId":"00227774474014694265"}}},"source":["import torch\n","import torch.nn as nn"],"execution_count":34,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NcjCbeEQqPSI"},"source":["- Convolution Layer 예시 (1)\n"]},{"cell_type":"code","metadata":{"id":"NQ7Y0tCOpkhM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675158049702,"user_tz":-540,"elapsed":343,"user":{"displayName":"조현습","userId":"00227774474014694265"}},"outputId":"e0e53a44-83b8-49f7-f931-62d37aec272a"},"source":["m = nn.Conv2d(16, 33, 3, stride=2)\n","m = nn.Conv2d(16, 33, (3, 5), stride=(2, 1), padding=(4, 2))\n","m = nn.Conv2d(16, 33, (3, 5), stride=(2, 1), padding=(4, 2), dilation=(3, 1))\n","input = torch.randn(20, 16, 50, 100)\n","print(input.shape)\n","output = m(input)"],"execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([20, 16, 50, 100])\n"]}]},{"cell_type":"code","metadata":{"id":"RLqGbclbp3_N","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675157999977,"user_tz":-540,"elapsed":3,"user":{"displayName":"조현습","userId":"00227774474014694265"}},"outputId":"17b46b3a-f5e1-4ac8-9424-40114fec00d0"},"source":["output.shape"],"execution_count":36,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([20, 33, 26, 100])"]},"metadata":{},"execution_count":36}]},{"cell_type":"markdown","metadata":{"id":"CYeGAJEuneqW"},"source":["### nn.functional 패키지\n","\n","- 가중치를 직접 선언하여 인자로 넣어줘야함\n","\n","- 예시)\n","  - Convolution functions\n","\n","  - Pooling functions\n","  \n","  - Non-linear activation functions\n","\n","  - Normalization functions\n","\n","  - Linear functions\n","\n","  - Dropout functions\n","  \n","  - Sparse functions\n","  \n","  - Distance functions\n","\n","  - Loss functions\n","  - ..\n","\n","- https://pytorch.org/docs/stable/nn.functional.html"]},{"cell_type":"code","metadata":{"id":"NpwbO9Dhpflm"},"source":[],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fUYaJ5aLqKed"},"source":["- Convolution Layer 예시 (2)"]},{"cell_type":"code","metadata":{"id":"GAWLQE2GouHP"},"source":[],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lWmSlFBrpms1"},"source":[],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Wah4RsmgrRDP"},"source":["## Torchvision\n","\n","- `transforms`: 전처리할 때 사용하는 메소드\n","\n","- `transforms`에서 제공하는 클래스 이외에  \n","  일반적으로 클래스를 따로 만들어 전처리 단계를 진행\n","  \n","  - 아래의 코드에서 다양한 전처리 기술 확인  \n","    https://pytorch.org/docs/stable/torchvision/transforms.html\n"]},{"cell_type":"code","metadata":{"id":"akvq4QWmqSil"},"source":[],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PKu5mzyTs-Qj"},"source":["- 예시)\n","  - `DataLoader`의 인자로 들어갈 `transform`을 미리 정의할 수 있음\n","\n","  - `Compose`를 통해 리스트 안에 순서대로 전처리 진행\n","\n","  - 대표적인 예로, `ToTensor`()를 하는 이유는  \n","   <u>torchvision이 PIL Image형태로만 입력을 받기 때문에</u> 데이터 처리를 위해서 Tensor형으로 변환해야함"]},{"cell_type":"code","metadata":{"id":"y6K7FH-Rs9my"},"source":[],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"I4l1GvIlslKa"},"source":["## utils.data\n","\n","- `Dataset`에는 다양한 데이터셋이 존재  \n","  - MNIST, CIFAR10, ...\n","\n","- `DataLoader`, `Dataset`을 통해  \n","  `batch_size`, `train`여부, `transform`등을 인자로 넣어 데이터를 어떻게 load할 것인지 정해줄 수 있음"]},{"cell_type":"code","metadata":{"id":"1wsZKY7-s2Vv"},"source":[],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lldpI2lquBu3"},"source":[],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fKddZnT1uQmT"},"source":[],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zrxymquLxeo8"},"source":["- `batch_size`만큼 데이터를 하나씩 가져옴"]},{"cell_type":"code","metadata":{"id":"hvgMIyF6uUuU"},"source":[],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YPUC0a0aw6OM"},"source":["<u>**(중요) torch에서는 channel(채널)이 앞에 옴**</u>\n","\n","- `channel first`\n","\n","- tensorflow, keras 등에서는 channel이 뒤에 옴(`channel last`)"]},{"cell_type":"markdown","metadata":{"id":"wuhylD3iyFYr"},"source":["### 데이터 확인"]},{"cell_type":"code","metadata":{"id":"C9hAQmQlul8P"},"source":[],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zDcUY6o4xUQp"},"source":[],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MZmPWiGbxoiW"},"source":[],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AUOdd4UaxaXO"},"source":[],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PDQfjw4wxr1z"},"source":[],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JDCVw59ax3-A"},"source":[],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JVcWQlxzihtS"},"source":["## 각 Layer 설명"]},{"cell_type":"code","metadata":{"id":"IGXn1_weif5H"},"source":[],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"73kJ3heBi26y"},"source":["### nn.Conv2d\n","\n","- `in_channels`: channel의 갯수\n","\n","- `out_channels`: 출력 채널의 갯수\n","\n","- `kernel_size`: 커널(필터) 사이즈\n","\n","- 텐서플로우, 케라스와 다르게 레이어의 `input`인자에도 값을 집어 넣어줘야함"]},{"cell_type":"code","metadata":{"id":"RcHJguyFipTl"},"source":[],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iWiJbViHjFG0"},"source":[],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GxWYFm2xjUeN"},"source":["- `wegiht`확인"]},{"cell_type":"code","metadata":{"id":"za0enRbyjPzV"},"source":[],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MAZcTU2gjiCX"},"source":["- `weight`는 `detach()`를 통해 꺼내줘야 `numpy()`변환이 가능"]},{"cell_type":"code","metadata":{"id":"9eN_oUBkjT85"},"source":[],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kwso9tsijmz8"},"source":[],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mUegf6HPjdPl"},"source":[],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DMeTOqVmcdWa"},"source":[],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cvolnNsscdHs"},"source":[],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NLOAfD5mjup1"},"source":[],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"r50wFkl6j1sY"},"source":[],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZiIp-frJj2Hl"},"source":[],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uOHMu-UQkW3a"},"source":[],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6sCqGmH_kwHm"},"source":["### Pooling\n","- `F.max_pool2d` \n","  - `stride`\n","\n","  - `kernel_size`\n","\n","- `torch.nn.MaxPool2d` 도 많이 사용"]},{"cell_type":"code","metadata":{"id":"AYqPrLH1kxQl"},"source":[],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tvI8W_8Yk81S"},"source":[],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aV3HK4FulCaJ"},"source":["- MaxPool Layer는 weight가 없기 때문에 바로 `numpy()`변환 가능"]},{"cell_type":"code","metadata":{"id":"fseB_qlflBta"},"source":[],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6w8DQnNtlNCq"},"source":[],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"q7RVioKwlbH1"},"source":["### Linear\n","- 1d만 가능 `.view()`를 통해 1D로 펼쳐줘야함"]},{"cell_type":"code","metadata":{"id":"Kwcedadrlcbl"},"source":[],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_mYQy4I3lmAm"},"source":[],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6wgSmY0Zlofk"},"source":[],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LcJFqf0alsxr"},"source":[],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ewEpebSVluHz"},"source":[],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0IjPKDKRl3CV"},"source":["### Softmax"]},{"cell_type":"code","metadata":{"id":"obhBb3O-lzbs"},"source":[],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ljgOEyNMmBEE"},"source":[],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"18ymFSRAmBo7"},"source":[],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bYh13Bnj5wEN"},"source":["### F.relu\n","\n","- ReLU 함수를 적용하는 레이어\n","\n","- `nn.ReLU`로도 사용 가능"]},{"cell_type":"code","metadata":{"id":"D4VFePpR9_Ak"},"source":[],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1lKlSiaY5wZW"},"source":[],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0yuABl4h-yye"},"source":["## Optimizer\n","\n","- `import torch.optim as optim`\n","\n","- `model`의 파라미터를 업데이트\n","\n","- 예시)\n","  ```python\n","  optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5)\n","  optimizer = optim.SGD(model.parameters(), lr=0.001)\n","  ```\n","\n","- `.zero_grad()`로 초기화\n","- `.step()`으로 업데이트\n","\n"]}]}
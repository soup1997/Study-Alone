{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPvdyCyOAGnVBikfXAfFJcJ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## 밑바닥부터 시작하는 딥러닝 3장"],"metadata":{"id":"S95nozuqi4G8"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"6ePyk5XJVgpt"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import tensorflow.keras as keras\n","from PIL import Image"]},{"cell_type":"markdown","source":["## 3층 신경망"],"metadata":{"id":"L0TuyuFUfP9q"}},{"cell_type":"code","source":["def sigmoid(x):\n","  return 1 / (1 + np.exp(-x))\n","\n","# 일반적으로 Regression 문제에는 identity_function을, Classification 문제에는 softmax를 이용한다.\n","def identity_function(x):\n","  return x\n","\n","def softmax(a):\n","  c = np.max(a)\n","  exp_a = np.exp(a - c) # Overflow 방지(수식 참고)\n","  y = exp_a / np.sum(exp_a) # 0과 1사이의 범위를 가지는 실수, 또한 모든 출력의 총합은 1(확률과 동일)\n","  return y\n","\n","# define neural network\n","def init_network():\n","  network = {}\n","  network['W1'] = np.array([[0.1, 0.3, 0.5], [0.2, 0.4, 0.6]])\n","  network['b1'] = np.array([0.1, 0.2, 0.3])\n","  network['W2'] = np.array([[0.2, 0.4], [0.2, 0.5], [0.3, 0.6]])\n","  network['b2'] = np.array([0.1, 0.2])\n","  network['W3'] = np.array([[0.3, 0.3], [0.2], 0.4])\n","  network['b3'] = np.array([0.1, 0.2])\n","\n","  return network\n","\n","# 신경망의 순방향 연산\n","def forward(network, x):\n","  W1, W2, W3 = network['W1'], network['W2'], network['W3']\n","  b1, b2, b3 = network['b1'], network['b2'], network['b3']\n","\n","  # activation input, output\n","  a1 = np.dot(x, W1) + b1\n","  z1 = sigmoid(a1)\n","  a2 = np.dot(z1, W2) + b2\n","  z2 = sigmoid(a2)\n","  a3 = np.dot(z2, W3) + b3\n","  y = identity_function(a3)\n","\n","  return y"],"metadata":{"id":"12tNk41Lfd8J"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Classification"],"metadata":{"id":"xnzmhuzvsQh6"}},{"cell_type":"code","source":["import pickle\n","from google.colab import drive\n","\n","drive.mount('/content/drive')\n","file_path = '/content/drive/MyDrive/Colab Notebooks/sample_weight.pkl'\n","\n","def get_data():\n","  (x_train, t_train), (x_test, t_test) = keras.datasets.mnist.load_data()\n","  x_train = x_train.reshape(60000, -1)\n","  x_test = x_test.reshape(10000, -1)\n"," \n","  print('x_train.shape: ', x_train.shape)\n","  print('t_train.shape: ', t_train.shape)\n","  print('x_test.shape: ', x_test.shape)\n","  print('t_test.shape: ', t_test.shape)\n","\n","  return x_test, t_test\n","\n","# define neural network\n","def init_network():\n","  with open(file_path, 'rb') as f:\n","    network = pickle.load(f)\n","\n","  return network\n","\n","def print_shape(*args):\n","  for i in args:\n","    print('shape: {}'.format(i.shape))  \n","\n","# 신경망의 순방향 연산\n","def predict(network, x):\n","  W1, W2, W3 = network['W1'], network['W2'], network['W3']\n","  b1, b2, b3 = network['b1'], network['b2'], network['b3']\n","\n","  # activation input, output\n","  a1 = np.dot(x, W1) + b1\n","  z1 = sigmoid(a1)\n","  a2 = np.dot(z1, W2) + b2\n","  z2 = sigmoid(a2)\n","  a3 = np.dot(z2, W3) + b3\n","  y = softmax(a3)\n","\n","  return y"],"metadata":{"id":"zW7JJC5NozuQ","executionInfo":{"status":"ok","timestamp":1675151663778,"user_tz":-540,"elapsed":3831,"user":{"displayName":"조현습","userId":"00227774474014694265"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"ba78db09-a6bb-46ae-f5a8-ca1a572a6507"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["x, t = get_data()\n","network = init_network() \n","# W1: 도착지가 다음층의 1번노드, W2: 도착지가 다음층의 2번노드, W3: 도착지가 다음층의 3번 노드\n","W1, W2, W3 = network['W1'], network['W2'], network['W3']\n","print_shape(x[0], W1, W2, W3)\n","\n","'''\n","배치 크기(묶음),\n","배치 처리를 통해 느린 I/O동작을 통한 데이터를 읽는 횟수가 줄어, CPU나 GPU로 순수계산을 수행하는 비율이 높아짐\n","'''\n","batch_size = 100\n","accuracy_cnt = 0\n","\n","for i in range(0, len(x), batch_size): # len(x) is 10000\n","  x_batch = x[i:i+batch_size] # 1차원 인덱싱(각 행에 접근)\n","  y_batch = predict(network, x_batch)\n","  p = np.argmax(y_batch, axis=1) # 확률이 가장 높은 원소의 인덱스를 얻는다.\n","  accuracy_cnt += np.sum(p == t[i:i+batch_size])\n","\n","print('Accuracy:' + str(float(accuracy_cnt) / len(x)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"00Bp2QLmpQ__","executionInfo":{"status":"ok","timestamp":1675152633411,"user_tz":-540,"elapsed":946,"user":{"displayName":"조현습","userId":"00227774474014694265"}},"outputId":"7879924a-8985-464c-a55d-67c5ca5da9a1"},"execution_count":59,"outputs":[{"output_type":"stream","name":"stdout","text":["x_train.shape:  (60000, 784)\n","t_train.shape:  (60000,)\n","x_test.shape:  (10000, 784)\n","t_test.shape:  (10000,)\n","shape: (784,)\n","shape: (784, 50)\n","shape: (50, 100)\n","shape: (100, 10)\n","Accuracy:0.9207\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-53-44ed687684ba>:2: RuntimeWarning: overflow encountered in exp\n","  return 1 / (1 + np.exp(-x))\n"]}]},{"cell_type":"markdown","source":["# 신경망 각 층의 배열형상의 추이\n","> $X\\;\\;\\;\\;W1\\;\\;\\;\\;\\;\\;\\;\\;\\;W2\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;W3 \\;\\;\\;\\;\\;\\;\\rightarrow Y$   \n","> $784\\;\\;784*50\\;\\;50*100\\;\\;100*10\\;\\;\\;\\;10$"],"metadata":{"id":"ckODQzGk1GSA"}},{"cell_type":"markdown","source":["# 신경망 각 층의 배열형상의 추이(배치 적용)\n","> $X\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;W1\\;\\;\\;\\;\\;\\;\\;\\;\\;W2\\;\\;\\;\\;\\;\\;\\;\\;\\;W3 \\;\\;\\;\\;\\;\\;\\rightarrow Y$   \n","> $100*784\\;\\;784*50\\;\\;50*100\\;\\;100*10\\;\\;\\;\\;100*10$"],"metadata":{"id":"fAY2IkBi4OEv"}}]}